{
  "train_loss": [
    0.4682031273841858,
    0.46234182516733807,
    0.4552963574727376,
    0.44907551010449726,
    0.4467138151327769,
    0.4381985068321228
  ],
  "val_metrics": [
    {
      "hierarchical_final_micro_f1": 38.00602208096353,
      "hierarchical_final_macro_f1": 35.18510553507492,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.950819672131146,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.52092177249098,
      "epoch": 1
    },
    {
      "hierarchical_final_micro_f1": 38.00602208096353,
      "hierarchical_final_macro_f1": 35.18510553507492,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.950819672131146,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.52092177249098,
      "epoch": 2
    },
    {
      "hierarchical_final_micro_f1": 38.00602208096353,
      "hierarchical_final_macro_f1": 35.18510553507492,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.950819672131146,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.52092177249098,
      "epoch": 3
    },
    {
      "hierarchical_final_micro_f1": 38.00602208096353,
      "hierarchical_final_macro_f1": 35.18510553507492,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.950819672131146,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.52092177249098,
      "epoch": 4
    },
    {
      "hierarchical_final_micro_f1": 38.00602208096353,
      "hierarchical_final_macro_f1": 35.18510553507492,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.950819672131146,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.52092177249098,
      "epoch": 5
    },
    {
      "hierarchical_final_micro_f1": 37.64172335600907,
      "hierarchical_final_macro_f1": 34.9349409531131,
      "hierarchical_coarse_micro_f1": 53.06122448979591,
      "hierarchical_fine_micro_f1": 22.22222222222222,
      "hierarchical_coarse_macro_f1": 48.849289297658856,
      "hierarchical_fine_macro_f1": 21.020592608567345,
      "epoch": 6
    }
  ],
  "best_metrics": {
    "hierarchical_final_micro_f1": 38.00602208096353,
    "hierarchical_final_macro_f1": 35.18510553507492,
    "hierarchical_coarse_micro_f1": 53.06122448979591,
    "hierarchical_fine_micro_f1": 22.950819672131146,
    "hierarchical_coarse_macro_f1": 48.849289297658856,
    "hierarchical_fine_macro_f1": 21.52092177249098,
    "epoch": 1
  },
  "config": {
    "data_path": "/mnt/cfs/huangzhiwei/NLP-WED0910/datas/train_merged_origin+qwen256.json",
    "val_data_path": "/mnt/cfs/huangzhiwei/NLP-WED0910/datas/val.json",
    "model_name": "/mnt/cfs/huangzhiwei/NLP-WED0910/projects/models/bge-large-zh-v1.5",
    "num_coarse_labels": 4,
    "num_fine_labels": 14,
    "max_length": 128,
    "dropout": 0.3135999246870766,
    "num_experts": 15,
    "expert_dim": 512,
    "top_k": 1,
    "use_separate_moe": true,
    "load_balance_weight": 0.013540158381723238,
    "batch_size": 32,
    "lr": 1.86884655838032e-05,
    "weight_decay": 0.01,
    "epochs": 40,
    "patience": 5,
    "threshold": 0.31676353792873924,
    "seed": 3407,
    "distillation_alpha": 0.7,
    "distillation_temperature": 4.0,
    "results_dir": "training_results",
    "checkpoint_dir": "checkpoints",
    "device": "cuda"
  },
  "total_time_hours": 0.001560001638200548,
  "final_epoch": 6,
  "early_stopped": true
}