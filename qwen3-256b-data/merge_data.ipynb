{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 7 1\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "104\n",
      "Merged predictions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions.json', 'r', encoding='utf-8') as f:\n",
    "    data_1 = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_2.json', 'r', encoding='utf-8') as f:\n",
    "    data_2 = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_3.json', 'r', encoding='utf-8') as f:\n",
    "    data_3 = json.load(f)\n",
    "\n",
    "list1 = data_1['predictions']\n",
    "list2 = data_2['predictions']\n",
    "list3 = data_3['predictions']\n",
    "\n",
    "\n",
    "print(len(list1), len(list2), len(list3))\n",
    "print(type(list1), type(list2), type(list3))\n",
    "merged_list = list1 + list2 + list3\n",
    "\n",
    "print(len(merged_list))\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_merged.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(merged_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Merged predictions saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned predictions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# 通过检索里面的内容，看是否相同，从而更改对应的sent_id，并让顺序进行一个对齐。\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_merged.json', 'r', encoding='utf-8') as f:\n",
    "    merged_data = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/datas/train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "data = []\n",
    "\n",
    "for item in train_data:\n",
    "    sent = item['sent']\n",
    "    sent_id = item['sent_id']\n",
    "\n",
    "    for merged_item in merged_data:\n",
    "        if merged_item['sent'] == sent:\n",
    "            merged_item['sent_id'] = sent_id\n",
    "            data.append(merged_item)\n",
    "            break\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_merged_aligned.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Aligned predictions saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_merged_origin+qwen256.json saved.\n"
     ]
    }
   ],
   "source": [
    "# 合并train和qwen256b出来的标签和概率。\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/datas/train.json', 'r', encoding='utf-8') as f:\n",
    "    origin_train = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_merged_aligned.json', 'r', encoding='utf-8') as f:\n",
    "    qwen256_train = json.load(f)\n",
    "\n",
    "\n",
    "merge_train = []\n",
    "\n",
    "for i in range(len(origin_train)):\n",
    "    item = origin_train[i]\n",
    "    item_qwen256 = qwen256_train[i]\n",
    "    if item[\"sent\"] != item_qwen256[\"sent\"]:\n",
    "        print(item[\"sent\"])\n",
    "        print(item[\"sent_id\"])\n",
    "    data_dict={\n",
    "        \"sent_id\": item[\"sent_id\"],\n",
    "        \"sent\": item[\"sent\"],\n",
    "        \"CourseGrainedErrorType\": item[\"CourseGrainedErrorType\"],\n",
    "        \"FineGrainedErrorType\": item[\"FineGrainedErrorType\"],\n",
    "        \"CourseGrainedErrorType_qwen256\": item_qwen256[\"CourseGrainedErrorType\"],\n",
    "        \"FineGrainedErrorType_qwen256\": item_qwen256[\"FineGrainedErrorType\"],\n",
    "        \"coarse_probabilities_qwen256\": item_qwen256[\"coarse_probabilities\"],\n",
    "        \"fine_probabilities_qwen256\": item_qwen256[\"fine_probabilities\"]\n",
    "    }\n",
    "\n",
    "    merge_train.append(data_dict)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/datas/train_merged_origin+qwen256.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(merge_train, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"train_merged_origin+qwen256.json saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/datas/train.json', 'r', encoding='utf-8') as f:\n",
    "    origin_train = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/train_predictions_merged_aligned.json', 'r', encoding='utf-8') as f:\n",
    "    qwen256_train = json.load(f)\n",
    "\n",
    "\n",
    "for i in range(len(origin_train)):\n",
    "    sent_1 = origin_train[i]['sent']\n",
    "    flag = False\n",
    "    for j in range(len(qwen256_train)):\n",
    "        sent_2 = qwen256_train[j]['sent']\n",
    "        if sent_1 == sent_2:\n",
    "            flag = True\n",
    "    \n",
    "    if flag == False:\n",
    "        print(origin_train[i]['sent_id'])\n",
    "        print(sent_1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证预测结果已成功更新sent_id\n",
      "匹配统计: 27/27 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取数据文件\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/val_result.json', 'r', encoding='utf-8') as f:\n",
    "    data_predict = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/datas/val.json', 'r', encoding='utf-8') as f:\n",
    "    data_label = json.load(f)\n",
    "\n",
    "# 创建句子到sent_id的映射字典，提高查找效率\n",
    "sent_to_id = {item['sent']: item['sent_id'] for item in data_label}\n",
    "\n",
    "# 统计匹配情况\n",
    "matched_count = 0\n",
    "total_count = len(data_predict['predictions'])\n",
    "\n",
    "# 更新predictions中的sent_id\n",
    "for data in data_predict['predictions']:\n",
    "    sent = data['sent']\n",
    "    if sent in sent_to_id:\n",
    "        data['sent_id'] = sent_to_id[sent]\n",
    "        matched_count += 1\n",
    "    else:\n",
    "        print(f\"警告: 未找到匹配的句子: {sent[:50]}...\")  # 只显示前50个字符\n",
    "        # 可以选择设置默认值或跳过\n",
    "        # data['sent_id'] = None\n",
    "\n",
    "# 保存结果\n",
    "with open('/mnt/cfs/huangzhiwei/NLP-WED0910/qwen3-256b-data/val_result_update.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_predict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"验证预测结果已成功更新sent_id\")\n",
    "print(f\"匹配统计: {matched_count}/{total_count} ({matched_count/total_count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykt-hzw3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
